This script with implementation of Random Forest scored 75% accuracy in the kaggle test.

Date :09/09/18

I further went with other classifiers such as Gradient Boosting Algorithms,
and then With XGBoost Algo also,

Finally i ran combined voting classifier so that i can combine all the models i tried namely,
Stochastic Gradient Descent
Random Forest
kNN
Gradient Descent Boosting
and finally XGBoost

I used the hyperparameter  voting= hard for voting classifier and i couldnt use soft mode as it spitted some unknown errors(that i dont understand) all over the place.!

Now it has an accuracy of 77.46% B-)
